{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOS0jdCptGu5t7SE3eHnLy6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshunayak05/NLP/blob/main/NLP_Intro_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Synonym Replacement\n"
      ],
      "metadata": {
        "id": "8Z6TDu-YwJqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random  # used to select random words or action\n",
        "import nltk # import the nural language\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxZssdc9wVNZ",
        "outputId": "d665c73c-d212-4f46-a201-669074013fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"True movie was absolutely fantastic and enjoyable\""
      ],
      "metadata": {
        "id": "SfkcZXv5wuXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synonyms(word):\n",
        "    synonyms = set() # create an empty set to store unique synonyms\n",
        "    for syn in wordnet.synsets(word):\n",
        "      #each synset has multiple lemmas (word with the same meaning)\n",
        "        for lemma in syn.lemmas():\n",
        "            synonym = lemma.name().replace(\"_\", \" \") # Replace underscores in phrases like 'well_known'\n",
        "\n",
        "            #avoid replacing the word with itself (case -sensitive)\n",
        "            if synonym.lower() != word.lower():\n",
        "                synonyms.add(synonym) # add to the set\n",
        "    return list(synonyms) # convert set to list and return\n",
        "\n",
        "def synonym_replacement(text,n=2):\n",
        "  #tokenize the sentence into words\n",
        "  words = nltk.word_tokenize(text)\n",
        "\n",
        "  # Make a copy of the words to modify\n",
        "  new_words = words.copy()\n",
        "  # filter to include only alphabetic words (ignore punctuations , numbers , etc.)\n",
        "  random_word_list = list(set([word for word in words if word not in new_words]))\n",
        "  #shuffle the  list to randomly select words for replacement\n",
        "  random.shuffle(random_word_list)\n",
        "\n",
        "  num_replaced=0 # keep track of how many words we replaced\n",
        "\n",
        "  # go through words one by one\n",
        "  for word in random_word_list:\n",
        "    synonyms = get_synonyms(word) #get synonyms of the word\n",
        "    if synonyms:\n",
        "      #Choose a random synonym from the list\n",
        "      synonyms=random.choice(synonyms)\n",
        "      # Replace the word in the sentence with the synonym\n",
        "      new_words =[synonyms if w == word else w for w in new_words]\n",
        "      num_replaced +=1 #Increase the replacement count\n",
        "\n",
        "    #stop if we have replaces n words\n",
        "    if num_replaced >=n:\n",
        "      break\n",
        "  # join the list back into a sentence\n",
        "  return ' '.join(new_words)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xaJwyuD7w5bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "original =\"The movie was absolutely fantastic and enjoyable\"\n",
        "augmentated = synonym_replacement(original,n=2)\n",
        "print(\"Original:\",original)\n",
        "print(\"Augmented:\",augmentated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYlGU0fx0Lka",
        "outputId": "0c5d4cc5-342a-4a06-e0b9-e9e9a83a599e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: The movie was absolutely fantastic and enjoyable\n",
            "Augmented: The movie was absolutely fantastic and enjoyable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2,. Biagram\n"
      ],
      "metadata": {
        "id": "Mdza5pWn1h-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2 =\"The ram is a good boy\"\n",
        "augmentated2=biagram_flip(text2)\n",
        "print(\"Original:\",text2)\n",
        "print(\"Augmented:\",augmentated2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQsy2IVE28Sb",
        "outputId": "b6edde09-7d5d-406b-f485-793008221c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: The ram is a good boy\n",
            "Augmented: The ram is good a boy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 Back Translation"
      ],
      "metadata": {
        "id": "ZK03yGeX3f3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def biagram_flip(text):\n",
        "  # tokenize the input text into individual words(tokens)\n",
        "  words =nltk.word_tokenize(text)\n",
        "\n",
        "  new_words=words.copy() # make a copy of the words to modify\n",
        "\n",
        "  indices=list(range(len(words)-1)) # create a list of indices for the bigrams\n",
        " # If there are fewer than 2 words, there's no bigram to flip\n",
        "  if not indices:\n",
        "    return text\n",
        "\n",
        "  flip_index =random.choice(indices) # randomly select an index from the list\n",
        "  # Swap the two words at the selected bigram index\n",
        "  new_words[flip_index], new_words[flip_index+1] = new_words[flip_index+1], new_words[flip_index]\n",
        "\n",
        " #JOIN THE words back into a sentence and return\n",
        "  return ' '.join(new_words)"
      ],
      "metadata": {
        "id": "4S17Zc3M0adA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep_translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AWAaXOY5U9a",
        "outputId": "e028f804-2a2e-4620-8432-52762537464a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "#define a function for back translation\n",
        "def back_translate_verbose(text,intermedate_lang='fr'):\n",
        "  try:\n",
        "    translated = GoogleTranslator(source='auto',target=intermedate_lang).translate(text)\n",
        "    # step 2 translate back to english\n",
        "    back_translated = GoogleTranslator(source='auto',target='en').translate(translated)\n",
        "\n",
        "    print(f\"Original: {text}\")\n",
        "    print(f\"Translated to {intermedate_lang}: {translated}\")\n",
        "    print(f\"Back translated to English: {back_translated}\")\n",
        "\n",
        "    return back_translated\n",
        "  except Exception as e:\n",
        "    print(f\"Error during back translation: {e}\")\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "HGvIRM5H3RJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example usage"
      ],
      "metadata": {
        "id": "zsOFE5hZ4dvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text3 =\"The movie was absolutely fantastic and enjoyable\"\n",
        "augmentated3=back_translate_verbose(text3,intermedate_lang='fr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbGfTp2l5bfB",
        "outputId": "aac082e7-bcbe-4c55-917e-c5cb7787d00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: The movie was absolutely fantastic and enjoyable\n",
            "Translated to fr: Le film était absolument fantastique et agréable\n",
            "Back translated to English: The film was absolutely fantastic and pleasant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 Adding Noise\n",
        "1. Random character swap\n",
        "2. Random deletion'\n",
        "3."
      ],
      "metadata": {
        "id": "BaG_G7p35o5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Random Character swaps"
      ],
      "metadata": {
        "id": "NcNoruEj51pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def add_noise(text,noise_level=0.1):\n",
        "  # convert the string into a list of character (bcos list is immutable)\n",
        "  text_chars=list(text)\n",
        "# calculate the number of noisy operation to perfrom\n",
        "  num_noise_chars=int(len(text_chars)*noise_level)\n",
        "# loop to perform num_noisy random adjacent swaps\n",
        "  for _ in range(num_noise_chars):\n",
        "    # select a random index, ensuring there's a next character to swap with\n",
        "    index=random.randint(0,len(text_chars)-2)\n",
        "    # swap the current character with the next one (idx and idx+1)\n",
        "    text_chars[index],text_chars[index+1]=text_chars[index+1],text_chars[index]\n",
        "# join the modified character list back into a string and return\n",
        "  return ''.join(text_chars)"
      ],
      "metadata": {
        "id": "BkjnsKTg5kRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text4=\"The movie was absolutely fantastic and enjoyable\"\n",
        "augmentated4=add_noise(text4,noise_level=0.1)\n",
        "print(\"Original:\",text4)\n",
        "print(\"Augmented:\",augmentated4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQGS2bQN7PUd",
        "outputId": "b49b78df-6238-460a-d84c-e28f0b6d77bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: The movie was absolutely fantastic and enjoyable\n",
            "Augmented: Teh movie was asboultely fantastic and nejoyable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eo-bMaiu7U-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Text PREPROCESING\n",
        "\n",
        "a. Basic Cleaning"
      ],
      "metadata": {
        "id": "N3m61gE6r9et"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HTML Removal\n",
        "\n",
        "re.match() --find if return word otherwise return none"
      ],
      "metadata": {
        "id": "egjV3LdMsXR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "result =re.match('The',r'The cat is on the table')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6aDilbVtYCS",
        "outputId": "aa985ac9-0670-4619-c62f-ee6590e12014"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(0, 3), match='The'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HTML TAG REMOVAL\n"
      ],
      "metadata": {
        "id": "aHKKkT0pLsl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1=\"<p> the <b>movie</b> was <i>fantastic </i> and <a href ='#' enjoyable</a>.</p>\"\n",
        "import re\n",
        "def removal_html_tags(text):\n",
        "    pattern=re.compile('<.*?>')\n",
        "    return pattern.sub(r'',text1)\n",
        "\n",
        "print(removal_html_tags(text1))"
      ],
      "metadata": {
        "id": "V4gQpOK6sTt5",
        "outputId": "c559327a-5172-4cc2-9510-45bcfad798eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the movie was fantastic  and .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "URL Removal\n",
        "\n",
        "S+ for white space\n",
        "\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "JgQud46XLyZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text2=\"check out the data at https://www.google.com/search?q=wikipedia&sourceid=chrome&ie=UTF-8\"\n",
        "text3=\"google search here at www.google.com\"\n",
        "import re\n",
        "def remove_urls(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "print(remove_urls(text2))\n",
        "print(remove_urls(text3))\n"
      ],
      "metadata": {
        "id": "kwqE2061LpKN",
        "outputId": "f02853d0-bb3a-4055-d2a4-cd9812580669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "check out the data at \n",
            "google search here at \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove Punctuation"
      ],
      "metadata": {
        "id": "EQoNf5vnMuJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "id": "Bc-ws2TkMakB",
        "outputId": "319e8e10-b82b-47e1-f00e-6b70c34a3e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exclude=string.punctuation"
      ],
      "metadata": {
        "id": "a4dO60pwNMjM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(text):\n",
        "  for char in exclude:\n",
        "    text=text.replace(char,'')\n",
        "  return text"
      ],
      "metadata": {
        "id": "DIBex3JnNQr-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text5='remove. with. punctuation?'\n",
        "print(remove_punc(text5))"
      ],
      "metadata": {
        "id": "Nl6fHFf4NdV6",
        "outputId": "1e0e2af5-8609-45f3-fadb-31737400f82a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remove with punctuation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Spell check"
      ],
      "metadata": {
        "id": "EuANQwUzN6ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "qXcgdF4wNlUM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_text='thhis is noot just a classs itss a lecture class'\n",
        "textBlb=TextBlob(incorrect_text)\n",
        "print(textBlb.correct().string)"
      ],
      "metadata": {
        "id": "c1v2BMEVOAqN",
        "outputId": "ef928266-ef9e-4e0b-a8b2-ab5f7b1a5059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is not just a class its a lecture class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Emojis  Unicode Normalization   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UM-qPFoxOSTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_text=\"hey this is to convert emoji into a machine understandable format 👌😒\""
      ],
      "metadata": {
        "id": "VtvtMs_jOQJO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_text.encode(\"utf-8\")"
      ],
      "metadata": {
        "id": "Zx1Ejq2AOtMT",
        "outputId": "dcbc8773-a485-4c96-fcba-fca18141356e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'hey this is to convert emoji into a machine understandable format \\xf0\\x9f\\x91\\x8c\\xf0\\x9f\\x98\\x92'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PeY2e9aZO0O0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}