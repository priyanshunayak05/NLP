{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcnGvTnrVdm4UqSsS/MFE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d6134a424b44d059971838d3f96f7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a925ff26c5b3448397ca8a7b0ecb9bf1",
              "IPY_MODEL_af2b6479f37a4ebab21215730904aac3",
              "IPY_MODEL_eb5cfea6bc434b3bb4f2fd98eb8ecc9c"
            ],
            "layout": "IPY_MODEL_3c82bbc4223d436f9efbb969c353291f"
          }
        },
        "a925ff26c5b3448397ca8a7b0ecb9bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3673f32912d42bca6ae3ad2872dc70f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_34bf7b374b5d4e0fb8a9096e9e322933",
            "value": "pytorch_model.bin:‚Äá100%"
          }
        },
        "af2b6479f37a4ebab21215730904aac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c91edb9def048fdbc17521018c4190b",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_340ae561530145e6abe4b7e8b539b316",
            "value": 440473133
          }
        },
        "eb5cfea6bc434b3bb4f2fd98eb8ecc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6d58487bd44a62aeb99ee165fa83c1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_993c134206c3440ca8bf3835fba5c1ed",
            "value": "‚Äá440M/440M‚Äá[00:05&lt;00:00,‚Äá134MB/s]"
          }
        },
        "3c82bbc4223d436f9efbb969c353291f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3673f32912d42bca6ae3ad2872dc70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34bf7b374b5d4e0fb8a9096e9e322933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c91edb9def048fdbc17521018c4190b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340ae561530145e6abe4b7e8b539b316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f6d58487bd44a62aeb99ee165fa83c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "993c134206c3440ca8bf3835fba5c1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshunayak05/NLP/blob/main/Assignment1_BERT(Pretrained_model)_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbuEx4SzbAZw",
        "outputId": "fe9f25f6-e2c9-429d-ca18-03f202777467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers # only run this once per kernel session - dont want to overload kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import transformers as ppb # BERT Model\n",
        "import tensorflow as tf\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load your CSV file (make sure it's uploaded in Colab or mounted from Drive)\n",
        "df = pd.read_csv(\"/content/funny_texts.csv\")\n",
        "# If your dataset columns are named `text` and `label`, this works directly:\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "# Split into train/test sets (same format as Kaggle version)\n",
        "train_x, test_x, train_y, test_y = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", len(train_x))\n",
        "print(\"Testing samples:\", len(test_x))"
      ],
      "metadata": {
        "id": "UNVvCFZCbLrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3908d002-34ec-44e0-8c0a-b659b3956f5b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 48\n",
            "Testing samples: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why we use HuggingFace?**\n",
        "\n",
        "HuggingFace is like a **library of pre-trained AI model**s.\n",
        "\n",
        "It provides ready-made models (like BERT, GPT, RoBERTa, T5, etc.).\n",
        "\n",
        "It also provides tokenizers (to convert text ‚Üí tokens)."
      ],
      "metadata": {
        "id": "UETOi4k41LzA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deee3054"
      },
      "source": [
        "!rm -rf ~/.cache/huggingface/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ü§ñ Why we use PyTorch or TensorFlow then?**\n",
        "\n",
        "HuggingFace provides the models,\n",
        "But the models must run on a deep learning framework.\n",
        "\n",
        "\n",
        "HuggingFace gives the models,\n",
        "\n",
        "PyTorch/TensorFlow run the models."
      ],
      "metadata": {
        "id": "lFyFLRP51ZaC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_nhkb_cfZgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9218b34",
        "outputId": "a05dfac4-8700-4aca-8ba8-975512480477"
      },
      "source": [
        "import transformers\n",
        "import tensorflow\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "print(f\"TensorFlow version: {tensorflow.__version__}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.57.1\n",
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT stands for **Bidirectional Encoder Representations from Transformers**.\n",
        "\n",
        "It is a pre-trained deep learning language model created by Google.\n",
        "\n",
        "In simple words:\n",
        "\n",
        "BERT is a ready-made brain that already understands English, because it has been trained on millions of sentences (Wikipedia + Books).\n",
        "\n",
        "\n",
        "BERT is based on the Transformer Encoder\n",
        "\n",
        "üèãÔ∏è‚Äç‚ôÇÔ∏è Training Style\n",
        "\n",
        "BERT was pre-trained using two tasks:\n",
        "\n",
        "Task\tMeaning\n",
        "\n",
        "**Masked Language Modeling (MLM**)\t  Random words are masked and BERT predicts them\n",
        "\n",
        "**Next Sentence Prediction (NSP)**\tPredicts if one sentence logically follows another\n",
        "\n",
        "This makes BERT very good at understanding context and relationships in text.\n",
        "\n",
        "üß† Why is BERT special?\n",
        "\n",
        "Previous models understood text **left ‚Üí right** (one direction) or **right ‚Üí left.**\n",
        "\n",
        "But **BERT** reads the text in **both directions** at the same time (bidirectional).\n",
        "\n",
        "Example sentence:\n",
        "\n",
        "\"He went to the bank to deposit money.\"\n",
        "\n",
        "Here bank means financial institution, not river bank.\n",
        "BERT understands that because it looks at the words before and after it."
      ],
      "metadata": {
        "id": "i4pfJwxatWb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the main model and tokenizer setup.\n",
        "\n",
        "To tokenize our data, we use huggingface's BertTokenizer, which does some extra stuff on top of our own cleaning, like adding tokens like [CLS], and other necessary steps for BERT. We still have to do the same data cleaning that we had done previously, and so I copied over the steps from there into here.\n",
        "\n",
        "The model is the TFBertForSequenceClassification model, which is basically a seqeunce classifier (like we want). This is better than previous models since the classification step and fine-tuning step are packed into one step, making it easier for us to use and work with."
      ],
      "metadata": {
        "id": "F4UW5Lkwu2aW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "3d6134a424b44d059971838d3f96f7d3",
            "a925ff26c5b3448397ca8a7b0ecb9bf1",
            "af2b6479f37a4ebab21215730904aac3",
            "eb5cfea6bc434b3bb4f2fd98eb8ecc9c",
            "3c82bbc4223d436f9efbb969c353291f",
            "c3673f32912d42bca6ae3ad2872dc70f",
            "34bf7b374b5d4e0fb8a9096e9e322933",
            "1c91edb9def048fdbc17521018c4190b",
            "340ae561530145e6abe4b7e8b539b316",
            "2f6d58487bd44a62aeb99ee165fa83c1",
            "993c134206c3440ca8bf3835fba5c1ed"
          ]
        },
        "id": "8y5DcQdOkB6m",
        "outputId": "321d2700-ae02-41c7-b98a-121d7a07c0e3"
      },
      "source": [
        "# Attempt to load the model explicitly for TensorFlow and disable safetensors\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", from_pt=True, use_safetensors=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d6134a424b44d059971838d3f96f7d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ppb.AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "eMKPtGTyliR1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These data cleaning functions below perform the same functions as were done in the main data processing notebook:\n",
        "\n",
        "lemmatize() - lemmatizes the sentence input s, helps simplify model vocabulary\n",
        "\n",
        "lower() - lowercases all the words in the sentence inputs s - is a remnant of a previous iteration, but I kept it around since it did no harm\n",
        "\n",
        "clean() - a generalized cleaning function that does the two steps above + removes all numbers from data, list of sentences passed in\n",
        "\n",
        "tokenize() - tokenizes the list of sentences passed in text - this is what the BertTokenizer from the transformers library does. Returns an array of word vectors.\n",
        "\n",
        "process() - a combination of cleaning and tokenizing, a function really created for our ease of use"
      ],
      "metadata": {
        "id": "QLQUgXJtukjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize(s):\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    return \" \".join([wordnet_lemmatizer.lemmatize(w,'v') for w in s.split(\" \")])\n",
        "\n",
        "def lower(s):\n",
        "    return s.lower()\n",
        "\n",
        "def clean(data):\n",
        "    # Apply cleaning steps to each element in the pandas Series\n",
        "    data = data.apply(lambda x: lemmatize(x))\n",
        "    data = data.apply(lambda x: lower(x))\n",
        "    data = data.apply(lambda x: re.sub(r'\\d+', '', x)) # remove nums\n",
        "    return data\n",
        "\n",
        "def tokenize(text):\n",
        "    # Ensure text is a list of strings for batch processing\n",
        "    if isinstance(text, pd.Series):\n",
        "        text = text.tolist()\n",
        "    tokenized = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "    return tokenized\n",
        "\n",
        "def process(data):\n",
        "    cleaned = clean(data)\n",
        "    return tokenize(cleaned)"
      ],
      "metadata": {
        "id": "YXMVU2cwljBU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch = process(train_x)\n",
        "test_batch = process(test_x)"
      ],
      "metadata": {
        "id": "sK410V8ipj4R"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "842b3c81",
        "outputId": "0758b691-3be7-4a1d-df15-685ecdc20074"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 2e-5\n",
        "epochs = 10\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-8)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric1 = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "metric2 = tf.keras.metrics.Precision(name=\"precision\")\n",
        "metric3 = tf.keras.metrics.Recall(name=\"recall\")\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric1])"
      ],
      "metadata": {
        "id": "O-6FmC-npuwG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=train_batch.input_ids, y=np.array(train_y), epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e91TorV5r3Uj",
        "outputId": "76f008a1-b4c9-41e0-9769-e0a9475851e1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 66s 7s/step - loss: 0.6953 - accuracy: 0.5208\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 20s 7s/step - loss: 0.6205 - accuracy: 0.8542\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 20s 8s/step - loss: 0.5492 - accuracy: 0.9583\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 20s 7s/step - loss: 0.4804 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 21s 8s/step - loss: 0.3836 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 20s 6s/step - loss: 0.3014 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 21s 8s/step - loss: 0.2293 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 20s 7s/step - loss: 0.1943 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 26s 8s/step - loss: 0.1574 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 31s 12s/step - loss: 0.1242 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x=test_batch.input_ids, y=np.array(test_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTBCazXCsXrR",
        "outputId": "e324e21c-951b-405e-fffd-8063317dc556"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step - loss: 0.0963 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0963495671749115, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(x=test_batch.input_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcSrTnXztjtj",
        "outputId": "29f91fbb-63f2-4431-ac69-1a3afd679e1a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred[0].shape)  # 13 data point or 2 class hai  funny or not funny\n",
        "y_pred_bool = np.argmax(y_pred[0], axis=1) # sabse badha score jada hai\n",
        "print(np.array(test_y).shape)\n",
        "print(y_pred_bool)\n",
        "print(y_pred[0])\n",
        "print(classification_report(test_y, y_pred_bool,))\n",
        "\n",
        "# Macro average: Har class ka score lekar unka saadharan average nikaalna, yaani sabhi class ko barabar importance dena.\n",
        "\n",
        "# Weighted average: Har class ke score ko us class ke samples ki sankhya ke hisaab se weight dekar average nikaalna, taaki badi classes ka asar zyada dikhe.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxOlAPZZtr5u",
        "outputId": "149cd3b7-31c7-4bf2-f844-6cc1d51a1251"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13, 2)\n",
            "(13,)\n",
            "[0 1 1 0 1 0 1 0 0 1 0 1 0]\n",
            "[[ 1.368714   -1.5068904 ]\n",
            " [-0.86342055  1.0902638 ]\n",
            " [-0.94209534  1.1208786 ]\n",
            " [ 1.2954127  -1.5229827 ]\n",
            " [-0.8851504   1.1726055 ]\n",
            " [ 1.3456918  -1.5748606 ]\n",
            " [-0.86865395  1.1251256 ]\n",
            " [ 1.1863793  -1.2852141 ]\n",
            " [ 1.2930834  -1.2206954 ]\n",
            " [-0.8985639   1.1045573 ]\n",
            " [ 1.3265722  -1.654271  ]\n",
            " [-0.7067116   0.8390309 ]\n",
            " [ 1.2472755  -1.5546747 ]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00        13\n",
            "   macro avg       1.00      1.00      1.00        13\n",
            "weighted avg       1.00      1.00      1.00        13\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model.predict()** returns logits (raw model output scores) representing the probability of each class.\n",
        "\n",
        "It converts text into token IDs that your model can understand.\n",
        "\n",
        "Output contains:\n",
        "\n",
        "**input_ids** ‚Üí numerical tokens for each word/piece\n",
        "\n",
        "**attention_mask** ‚Üí tells the model which tokens are real (1) and which are padding (0)\n",
        "\n",
        "**token_type_ids** ‚Üí distinguishes sentence pairs (useful for tasks like question-answering), but still included here."
      ],
      "metadata": {
        "id": "eu8Vi5RRy672"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tk = tokenizer(\"When my son told me to stop impersonating a flamingo, I had to put my foot down.\", padding=True, return_tensors=\"tf\")\n",
        "out = model.predict(x=(tk.input_ids, tk.attention_mask, tk.token_type_ids))\n",
        "print(np.argmax(out[0], axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T_iv2k9tyOA",
        "outputId": "aadf1368-9f91-4ec0-e630-5dee9d05a439"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 252ms/step\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\"Prediction\":y_pred_bool})\n",
        "submission.to_csv(\"predictions.csv\", index=True, index_label=\"Id\")"
      ],
      "metadata": {
        "id": "pYwswcmwt4cg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qnqVKXoFuKQb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}